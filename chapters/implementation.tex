\subsection{Application plan}
\subsection{Web Audio API}
As the pitch detector is intended to be used in the browser, for portability and ease of use, the Web Audio API will be extensively used. The purpose of the API is to allow developers controls over audio processing functionality on browsers, by getting access to user audio devices, adding effects and more. 
The Web Audio API operates in a AudioContext, which can be thought of as an empty control flow graph. The graph is constructed using AudioNodes which fall into one of three categories; input or source nodes, modifier nodes and output nodes. The nodes are then connected to each other to form the graph.

\subsubsection{Sources and destinations}
The source node, as their names imply are entry points for audio control graph, they provide signals. Some of these include the OscillatorNode, a node which produces pure sinusoids, a MediaElementAudioSourceNode, which uses the media in an existing HTML audio element. As the purpose of the application is for the user to be able to record their own singing and have it analyzed for pitch correctness, the source in this case will be a MediaStreamAudioSourceNode, which provides a source signal from a MediaStream. The actual source will the method navigator.mediaDevices.getUserMedia\(\) that provides the MediaStream, but this is technically outside the AudioContext so it's not a source node.  
The output may be either the user's system's speakers, or another MediaStream. In this case, there won't be an output node because it's simply not needed. The output will be the result of the fourier analysis.

\subsubsection{Modifiers} 
The modifier nodes are the nodes that are neither sources nor destinations, they take in the signal from a node, performs some transform on the signal, and then hands it over to the next node, or nodes, in the graph. Some of these nodes apply effects, like rever or gain, some can be used for visualizing audio, some can be used to split audio into separate channels for per-channel modification.

The available modifiers unfortunately do not help with the development of the pitch detector, so a lot of the would be done with Worklet nodes, a node that allows custom functionality. With this in mind, the simplest way is to not use the Audio API node-based framework, but to just take the output from the microphone and process data using function calls.
\subsection{Pitch detector architecture}
The pitch detector will take the form of a pipeline with 5 stages: recording, zero-pad, FFT, HPS and getting the note name. 

While the WebAudio API provides rich control over audio in the browser, the approach for this work will be much simpler.  

\subsection{Setting up the audio context}
\subsubsection{Audio processors}

\subsection{Post processing}
\subsubsection{MIDI number to semitone name}
The MIDI number is conveniant because it's a simple integer and a standard. However, for most people, the semitone name means more than the MIDI number. To convert the MIDI number to a semitone, two formulae can be derived using known MIDI numbers and their corresponding notenames. As the semitones repeat every octave and an octave consists of 12 semitones, the index that will be used to find the semitone is computed with modulo 12. The octave number is computed by rounding down the result of the MIDI number divided by 12. For some reason, the MIDI numbers misalign with the octave numbers, C0 being MIDI 12, the octave is shifted down one more step. 
\begin{lstlisting}[style=javascript]
function getSemitoneName(midiNumber) {
    const SEMITONES = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "B", "H"]

    const letter = SEMITONES[midiNumber % 12];
    const octaveNumber = parseInt(midiNumber/12) -1;

    return "" + letter + octaveNumber; 
}
\end{lstlisting}


\subsection{Integrating with VSS}
VSS is an initialism that will be used to refer to the host application that can compare the pitch detector result to the notes of a piece or song. 
% The big idea:
% source node (microphone) -> % 
% https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API
\subsection{The FFT implementation}
% The problem here is that I don't want to be restricted to an FFT window size of a power of 2
% https://github.com/indutny/fft.js/
